{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vitor-Sallenave/Formacao-em-NLP/blob/main/Spark/NLP_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "qGLunJJ2cMJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3205a423-e543-4d6d-b666-b23a5c664a75",
          "showTitle": false,
          "title": ""
        },
        "id": "NXYyxjlfbzKr"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import Tokenizer, StringIndexer, Word2Vec\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "# This object \"spark\" is the session name\n",
        "spark = SparkSession.builder.appName(\"nlp\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a9608be9-afe6-4dc6-8d27-2e0de6119720",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "JToTzpuUbzKt",
        "outputId": "193a13aa-6a92-447f-aa5a-4717cfc984fa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8c96d1d87684>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Here, we are doing a SQL query from the table \"spam\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select * from spam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                 )\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `spam` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [spam], [], false\n"
          ]
        }
      ],
      "source": [
        "# Here, we are doing a SQL query from the table \"spam\"\n",
        "spam = spark.sql(\"select * from spam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3af57f08-f186-465d-9cea-00830eee02ea",
          "showTitle": false,
          "title": ""
        },
        "id": "ZyTSAqvybzKt",
        "outputId": "b4a63223-ec19-42b8-c21f-5ad2212375fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n|Category|             Message|\n+--------+--------------------+\n|     ham|Go until jurong p...|\n|     ham|Ok lar... Joking ...|\n|    spam|Free entry in 2 a...|\n|     ham|U dun say so earl...|\n|     ham|Nah I don't think...|\n+--------+--------------------+\nonly showing top 5 rows\n\n"
          ]
        }
      ],
      "source": [
        "# Showing the table\n",
        "spam.show(5, truncate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "67792de2-f28d-4b8c-8da2-26193a734d25",
          "showTitle": false,
          "title": ""
        },
        "id": "5KHt9lKsbzKu",
        "outputId": "35f07b09-df1d-4fec-8669-1be136a649ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+-------------+\n|Category|             Message|CategoryIndex|\n+--------+--------------------+-------------+\n|     ham|Go until jurong p...|          0.0|\n|     ham|Ok lar... Joking ...|          0.0|\n|    spam|Free entry in 2 a...|          1.0|\n|     ham|U dun say so earl...|          0.0|\n|     ham|Nah I don't think...|          0.0|\n+--------+--------------------+-------------+\nonly showing top 5 rows\n\n"
          ]
        }
      ],
      "source": [
        "# Transforming the category column into numbers\n",
        "stringIdx = StringIndexer(inputCol=\"Category\", outputCol=\"CategoryIndex\")\n",
        "spam_indexed = stringIdx.fit(spam).transform(spam)\n",
        "spam_indexed.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a30bd8ee-dbef-4249-a6c0-b6b8c4d64a64",
          "showTitle": false,
          "title": ""
        },
        "id": "19Nxc4tsbzKu",
        "outputId": "130c0c5d-12cd-46fb-adbc-83dc3dccb11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+-------------+--------------------+\n|Category|             Message|CategoryIndex|       MessageTokens|\n+--------+--------------------+-------------+--------------------+\n|     ham|Go until jurong p...|          0.0|[go, until, juron...|\n|     ham|Ok lar... Joking ...|          0.0|[ok, lar..., joki...|\n|    spam|Free entry in 2 a...|          1.0|[free, entry, in,...|\n|     ham|U dun say so earl...|          0.0|[u, dun, say, so,...|\n|     ham|Nah I don't think...|          0.0|[nah, i, don't, t...|\n+--------+--------------------+-------------+--------------------+\nonly showing top 5 rows\n\n"
          ]
        }
      ],
      "source": [
        "# Creating tokens\n",
        "tk = Tokenizer(inputCol=\"Message\", outputCol=\"MessageTokens\")\n",
        "spam_tokens = tk.transform(spam_indexed)\n",
        "spam_tokens.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ecd7353c-1cc7-4402-8a4c-97dbdbd3e706",
          "showTitle": false,
          "title": ""
        },
        "id": "N3AoBVo0bzKu",
        "outputId": "b084130a-4285-4827-cb8a-ca104cb6f88c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n|       MessageTokens|\n+--------------------+\n|[go, until, juron...|\n|[ok, lar..., joki...|\n|[free, entry, in,...|\n|[u, dun, say, so,...|\n|[nah, i, don't, t...|\n+--------------------+\nonly showing top 5 rows\n\n"
          ]
        }
      ],
      "source": [
        "# Selecting a column\n",
        "spam_tokens.select(\"MessageTokens\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "22f81ad3-b07a-465c-8b0a-77d252eabe1e",
          "showTitle": false,
          "title": ""
        },
        "id": "N6rqV5pfbzKv"
      },
      "outputs": [],
      "source": [
        "# Creating the vectors\n",
        "word2vec = Word2Vec(inputCol=\"MessageTokens\", outputCol=\"Messages2Vec\")\n",
        "spam_vectors = word2vec.fit(spam_tokens).transform(spam_tokens)\n",
        "spam_vectors.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "17c85b02-7525-4182-bf1a-4b473dc4e289",
          "showTitle": false,
          "title": ""
        },
        "id": "yoo2Ix7fbzKv"
      },
      "outputs": [],
      "source": [
        "spam_tokens.select(\"Messages2Vec\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "92146016-d506-4004-8159-a243ee438b51",
          "showTitle": false,
          "title": ""
        },
        "id": "MsIljDaCbzKv"
      },
      "outputs": [],
      "source": [
        "# Spliting the data into train and test\n",
        "spam_train, spam_test = spam_vectors.randomSplit([0.7, 0.3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "769ec962-a5a1-4022-bd53-5c88ebe0b410",
          "showTitle": false,
          "title": ""
        },
        "id": "S4bsOUW-bzKv"
      },
      "outputs": [],
      "source": [
        "# Creating the model\n",
        "rf = RandomForest(labelCol=\"CategoryIndex\", featuresCol=\"Messages2Vec\", numTrees=500)\n",
        "rf.fit(spam_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b1279fe3-a807-4c6e-872e-88562906cd89",
          "showTitle": false,
          "title": ""
        },
        "id": "lwLU87A6bzKv"
      },
      "outputs": [],
      "source": [
        "predictions = rf.transform(spam_test)\n",
        "predictions.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e0030398-0659-4d6d-8d9c-e6c23ffa20e9",
          "showTitle": false,
          "title": ""
        },
        "id": "3YAPJuovbzKv"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "bce = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
        "                                        labelCol=\"CategoryIndex\",\n",
        "                                        metricName=\"areaUnderROC\")\n",
        "result = bce.evaluate(predictions)\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "NLP Spark",
      "widgets": {}
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}